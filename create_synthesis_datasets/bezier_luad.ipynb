{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d180038f",
   "metadata": {},
   "source": [
    "# README\n",
    "Run this notebook to create the dataset for mosaic training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0cf606-ded3-45c0-8c42-ad3d650c8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage import morphology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079032f0-5e42-4caf-9bfe-e7f0a3a3dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_label(filename):\n",
    "    label_str = '[' + filename.split('[')[-1].split(']')[0] + ']'\n",
    "    if ',' not in label_str:\n",
    "        if ' ' in label_str:\n",
    "            # [0 0 0 1]\n",
    "            label_str = label_str.replace(' ', ',')\n",
    "        else:\n",
    "            # [0001]\n",
    "            label_str = str([int(i) for i in label_str[1:-1]])\n",
    "    label = eval(label_str)\n",
    "    return label\n",
    "\n",
    "def create_data(train_data):\n",
    "    only_tum_list = []\n",
    "    only_nec_list = []\n",
    "    only_lym_list = []\n",
    "    only_tas_list = []\n",
    "    train_image_list = os.listdir(train_data)\n",
    "    for name in train_image_list:\n",
    "        big_label = get_patch_label(name)\n",
    "        if np.sum(big_label) == 1:\n",
    "            train_image = os.path.join(train_data, name)\n",
    "            if big_label[0] == 1:\n",
    "                only_tum_list.append(train_image)\n",
    "            elif big_label[1] == 1:\n",
    "                only_nec_list.append(train_image)\n",
    "            elif big_label[2] == 1:\n",
    "                only_lym_list.append(train_image)\n",
    "            elif big_label[3] == 1:\n",
    "                only_tas_list.append(train_image)\n",
    "\n",
    "    return only_tum_list, only_nec_list, only_lym_list, only_tas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ebd56-9db0-4c41-851c-393b192e8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(region):\n",
    "    gray = cv2.cvtColor(region, cv2.COLOR_RGB2GRAY)\n",
    "    ret, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    binary = np.uint8(binary)    \n",
    "    dst = morphology.remove_small_objects(binary==255,min_size=50,connectivity=1)\n",
    "    mask = np.array(dst, dtype=np.uint8)\n",
    "    mask = mask * 255\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e73b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import binom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bernstein = lambda n, k, t: binom(n,k)*t **k * (1.-t)**(n-k)\n",
    "\n",
    "def bezier(points, num=200):\n",
    "    N = len(points)\n",
    "    t = np.linspace(0, 1, num=num)\n",
    "    curve = np.zeros((num, 2))\n",
    "    for i in range(N):\n",
    "        curve += np.outer(bernstein(N - 1, i, t), points[i])\n",
    "    return curve\n",
    "\n",
    "# generate cubic bezier curves\n",
    "class Segment():\n",
    "    def __init__(self, p1, p2, angle1, angle2, **kw):\n",
    "        self.p1 = p1; self.p2 = p2\n",
    "        self.angle1 = angle1; self.angle2 = angle2\n",
    "        self.numpoints = kw.get(\"numpoints\", 100)\n",
    "        r = kw.get(\"r\", 0.3)\n",
    "        d = np.sqrt(np.sum((self.p2-self.p1)**2))\n",
    "        self.r = r*d\n",
    "        self.p = np.zeros((4,2))\n",
    "        self.p[0,:] = self.p1[:]\n",
    "        self.p[3,:] = self.p2[:]\n",
    "        self.calc_intermediate_points(self.r)\n",
    "\n",
    "    def calc_intermediate_points(self,r):\n",
    "        self.p[1,:] = self.p1 + np.array([self.r*np.cos(self.angle1),\n",
    "                                    self.r*np.sin(self.angle1)])\n",
    "        self.p[2,:] = self.p2 + np.array([self.r*np.cos(self.angle2+np.pi),\n",
    "                                    self.r*np.sin(self.angle2+np.pi)]) # make sure the curve is C1 continuous\n",
    "        self.curve = bezier(self.p,self.numpoints)\n",
    "\n",
    "\n",
    "def get_curve(points, **kw):\n",
    "    segments = []\n",
    "    for i in range(len(points)-1):\n",
    "        seg = Segment(points[i,:2], points[i+1,:2], points[i,2],points[i+1,2],**kw)\n",
    "        segments.append(seg)\n",
    "    curve = np.concatenate([s.curve for s in segments])\n",
    "    return segments, curve\n",
    "\n",
    "def ccw_sort(p): # counter clockwise sort\n",
    "    d = p-np.mean(p,axis=0)\n",
    "    s = np.arctan2(d[:,0], d[:,1])\n",
    "    return p[np.argsort(s),:]\n",
    "\n",
    "def get_bezier_curve(a, rad=0.2, edgy=0):\n",
    "    \"\"\" given an array of points *a*, create a curve through\n",
    "    those points. \n",
    "    *rad* is a number between 0 and 1 to steer the distance of\n",
    "          control points.\n",
    "    *edgy* is a parameter which controls how \"edgy\" the curve is,\n",
    "           edgy=0 is smoothest.\"\"\"\n",
    "    p = np.arctan(edgy)/np.pi+.5\n",
    "    a = ccw_sort(a)\n",
    "    a = np.append(a, np.atleast_2d(a[0,:]), axis=0)\n",
    "    d = np.diff(a, axis=0)\n",
    "    ang = np.arctan2(d[:,1],d[:,0])\n",
    "    f = lambda ang : (ang>=0)*ang + (ang<0)*(ang+2*np.pi) # map angles to range(0,2pi)\n",
    "    ang = f(ang)\n",
    "    ang1 = ang\n",
    "    ang2 = np.roll(ang,1)\n",
    "    ang = p*ang1 + (1-p)*ang2 + (np.abs(ang2-ang1) > np.pi )*np.pi \n",
    "    ang = np.append(ang, [ang[0]])\n",
    "    a = np.append(a, np.atleast_2d(ang).T, axis=1) # x, y, angle\n",
    "    s, c = get_curve(a, r=rad, method=\"var\") \n",
    "    x,y = c.T\n",
    "    return x,y, a\n",
    "\n",
    "\n",
    "def get_random_points(n=5, scale=0.8, mindst=None, rec=0):\n",
    "    \"\"\" create n random points in the unit square, which are *mindst*\n",
    "    apart, then scale them.\"\"\"\n",
    "    mindst = mindst or .7/n\n",
    "    a = np.random.rand(n,2)\n",
    "    d = np.sqrt(np.sum(np.diff(ccw_sort(a), axis=0), axis=1)**2)\n",
    "    if np.all(d >= mindst) or rec>=200:\n",
    "        return a*scale\n",
    "    else:\n",
    "        return get_random_points(n=n, scale=scale, mindst=mindst, rec=rec+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bezier_mask(n, scale, rad=0.2, edgy=0.05):\n",
    "    a = get_random_points(n=n, scale=scale)\n",
    "    x, y, _ = get_bezier_curve(a,rad=rad, edgy=edgy)\n",
    "    x = np.round(x)\n",
    "    y = np.round(y)\n",
    "    mask = np.zeros((scale, scale), dtype=np.uint8)\n",
    "    mask = cv2.fillPoly(mask, np.int32([np.stack([x, y], axis=1)]), 1)\n",
    "    return mask\n",
    "\n",
    "def get_onelabel_mask(category, scale):\n",
    "    if category == \"tum\":\n",
    "        return np.zeros((scale, scale), dtype=np.uint8)\n",
    "    elif category == \"nec\":\n",
    "        return np.ones((scale, scale), dtype=np.uint8)\n",
    "    elif category == \"lym\":\n",
    "        return (np.ones((scale, scale), dtype=np.uint8) * 2)\n",
    "    else:\n",
    "        return (np.ones((scale, scale), dtype=np.uint8) * 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3014662",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/LUAD-HistoSeg/train/\"\n",
    "only_tum_list, only_nec_list, only_lym_list, only_tas_list = create_data(train_dir)\n",
    "dataset_dict = {\n",
    "    \"tum\": only_tum_list,\n",
    "    \"nec\": only_nec_list,\n",
    "    \"lym\": only_lym_list,\n",
    "    'tas': only_tas_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d282d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_one(n=12, rad=0.2, edgy=0.05, background_class=\"tum\", foreground_class=\"nec\"):\n",
    "    background_image_path = random.choice(dataset_dict[background_class])\n",
    "    foreground_image_path = random.choice(dataset_dict[foreground_class])\n",
    "\n",
    "    background_image = np.array(Image.open(background_image_path).resize((224, 224)))\n",
    "    foreground_image = np.array(Image.open(foreground_image_path).resize((224, 224)))\n",
    "\n",
    "    background_mask = get_onelabel_mask(background_class, scale=224)\n",
    "    foreground_mask = get_onelabel_mask(foreground_class, scale=224)\n",
    "\n",
    "    bezier_mask = get_bezier_mask(n=n, scale=224, rad=rad, edgy=edgy)\n",
    "\n",
    "    synthesized_image = bezier_mask[:,:,np.newaxis] * foreground_image + (1 - bezier_mask)[:,:,np.newaxis] * background_image\n",
    "    synthesized_mask = bezier_mask * foreground_mask + (1 - bezier_mask) * background_mask\n",
    "\n",
    "    return synthesized_image, synthesized_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb408d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_and_save(save_dir, i, n=12, rad=0.2, edgy=0.05, background_class=\"tum\", foreground_class=\"nec\"):\n",
    "    synthesized_image, synthesized_mask = synthesize_one(n, rad, edgy, background_class, foreground_class)\n",
    "    synthesized_image = Image.fromarray(synthesized_image)\n",
    "    palette = [0]*15\n",
    "    palette[0:3] = [205,51,51]          # Tumor epithelial (TE)\n",
    "    palette[3:6] = [0,255,0]            # Necrosis (NEC)\n",
    "    palette[6:9] = [65,105,225]         # Lymphocyte (LYM)\n",
    "    palette[9:12] = [255,165,0]         # Tumor-associated stroma (TAS)\n",
    "    palette[12:15] = [255, 255, 255]    # White background or exclude\n",
    "    synthesized_mask = Image.fromarray(np.uint8(synthesized_mask), mode='P')\n",
    "    synthesized_mask.putpalette(palette)\n",
    "\n",
    "    label = [0, 0, 0, 0]\n",
    "    if 'tum' in [background_class, foreground_class]:\n",
    "        label[0] = 1\n",
    "    if 'nec' in [background_class, foreground_class]:\n",
    "        label[1] = 1\n",
    "    if 'lym' in [background_class, foreground_class]:\n",
    "        label[2] = 1\n",
    "    if 'tas' in [background_class, foreground_class]:\n",
    "        label[3] = 1\n",
    "\n",
    "    synthesized_image.save(os.path.join(save_dir, 'img', f\"{i:05d}-{label}.png\"))\n",
    "    synthesized_mask.save(os.path.join(save_dir, 'mask', f\"{i:05d}-{label}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(0, 1):\n",
    "\n",
    "    save_dir = f\"../data/LUAD-HistoSeg/bezier224_5_0.2_0.05_1d1_run{run}\"\n",
    "\n",
    "    if not os.path.exists(os.path.join(save_dir, 'img')):\n",
    "        os.makedirs(os.path.join(save_dir, 'img'))\n",
    "    if not os.path.exists(os.path.join(save_dir, 'mask')):\n",
    "        os.makedirs(os.path.join(save_dir, 'mask'))\n",
    "\n",
    "    N_train = 10_000\n",
    "    for i in tqdm(range(N_train), total=N_train):\n",
    "        background_class, foreground_class = np.random.choice(['tum', 'nec', 'lym', 'tas'], size=2, replace=False)\n",
    "        synthesize_and_save(save_dir, i, background_class=background_class, \n",
    "        foreground_class=foreground_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa018ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wsss4luad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "153d7fbbbee1d273a0ca8d1411d96d9bc2f994be0d513b7341e48284653310bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
