{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_list[idx])\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dname in ['mosaic_2_112', 'bezier224_5_0.2_0.05_1d1']:\n",
    "    for run in range(0, 1):\n",
    "        train_image_dir = '../data/WSSS4LUAD/1.training'\n",
    "        no_stain_norm_synthesize_image_dir = f\"../data/WSSS4LUAD/{dname}_run{run}/img\"\n",
    "        log_dir = f'discriminate_logs/wsss4luad_disc_{dname}_run{run}.txt'\n",
    "\n",
    "        train_image_list = sorted([os.path.join(train_image_dir, i) for i in os.listdir(train_image_dir) if \".png\" in i])\n",
    "        real_image_list = []\n",
    "        for image_name in train_image_list:\n",
    "            label_str = '[' + image_name.split(']')[0].split('[')[-1] + ']'\n",
    "            label = eval(label_str)\n",
    "            if sum(label) > 1:\n",
    "                real_image_list.append(image_name)\n",
    "\n",
    "        synthesize_image_list = sorted([os.path.join(no_stain_norm_synthesize_image_dir, i) for i in os.listdir(no_stain_norm_synthesize_image_dir) if \".png\" in i])\n",
    "\n",
    "        np.random.shuffle(real_image_list)\n",
    "        np.random.shuffle(synthesize_image_list)\n",
    "\n",
    "        train_real_image_list = real_image_list[:int(len(real_image_list)*0.8)]\n",
    "        val_real_image_list = real_image_list[int(len(real_image_list)*0.8):]\n",
    "\n",
    "        train_synthesize_image_list = synthesize_image_list[:int(len(synthesize_image_list)*0.8)]\n",
    "        val_synthesize_image_list = synthesize_image_list[int(len(synthesize_image_list)*0.8):]\n",
    "\n",
    "        train_image_list = train_real_image_list + train_synthesize_image_list\n",
    "        train_label_list = [1] * len(train_real_image_list) + [0] * len(train_synthesize_image_list)\n",
    "\n",
    "        val_image_list = val_real_image_list + val_synthesize_image_list\n",
    "        val_label_list = [1] * len(val_real_image_list) + [0] * len(val_synthesize_image_list)\n",
    "\n",
    "\n",
    "        train_dataset = DiscriminatorDataset(train_image_list, train_label_list, transform=transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD)\n",
    "        ]))\n",
    "\n",
    "        val_dataset = DiscriminatorDataset(val_image_list, val_label_list, transform=transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD)\n",
    "        ]))\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "        model = timm.create_model('resnet18', pretrained=False, num_classes=2)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        metrics = torchmetrics.MetricCollection({ \n",
    "            'acc': torchmetrics.Accuracy(num_classes=2, average='micro'), \n",
    "            'prec': torchmetrics.Precision(num_classes=2, average='macro'), \n",
    "            'rec': torchmetrics.Recall(num_classes=2, average='macro'),\n",
    "            'f1': torchmetrics.F1Score(num_classes=2, average='macro')\n",
    "        }).cuda()\n",
    "\n",
    "        neg_metrics = torchmetrics.MetricCollection({ \n",
    "            'acc': torchmetrics.Accuracy(task='binary'), \n",
    "            'prec': torchmetrics.Precision(task='binary'), \n",
    "            'rec': torchmetrics.Recall(task='binary'),\n",
    "            'f1': torchmetrics.F1Score(task='binary')\n",
    "        }).cuda()\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "        EPOCH_NUM = 5\n",
    "        best_acc = 0\n",
    "        train_loss_list = []\n",
    "        val_metrics_list = []\n",
    "        for epoch in range(EPOCH_NUM):\n",
    "            print(f\"Epoch {epoch+1}/{EPOCH_NUM}\")\n",
    "            model.train()\n",
    "            loss_list = []\n",
    "            for batch in tqdm(train_dataloader, desc='train'):\n",
    "                image, label = batch\n",
    "                image = image.cuda()\n",
    "                label = label.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(image) # 1 real, 0 fake\n",
    "                loss = criterion(output, label)\n",
    "                loss_list.append(loss.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(f'train_loss: {np.mean(loss_list)}')\n",
    "            train_loss_list.append(np.mean(loss_list))\n",
    "\n",
    "            model.eval()\n",
    "            for batch in tqdm(val_dataloader, desc='val'):\n",
    "                image, label = batch\n",
    "                image = image.cuda()\n",
    "                label = label.cuda()\n",
    "                with torch.no_grad():\n",
    "                    output = model(image)\n",
    "                metrics(output, label)\n",
    "                neg_metrics(preds=output[:,0], target=1-label)\n",
    "            \n",
    "            metrics_dict = metrics.compute()\n",
    "            neg_metrics_dict = neg_metrics.compute()\n",
    "            metrics.reset()\n",
    "            neg_metrics.reset()\n",
    "\n",
    "            val_metrics_list.append(metrics_dict)\n",
    "            if metrics_dict['acc'] > best_acc:\n",
    "                best_acc = metrics_dict['acc']\n",
    "                if not os.path.exists('weights'):\n",
    "                    os.makedirs('weights')\n",
    "                torch.save(model.state_dict(), f\"weights/dis_{dname}_r18_e5_run{run}.pth\")\n",
    "            print({k: v.item() for k, v in metrics_dict.items()})\n",
    "            print({k: v.item() for k, v in neg_metrics_dict.items()})\n",
    "\n",
    "            if not os.path.exists('discriminate_logs'):\n",
    "                os.makedirs('discriminate_logs')\n",
    "            with open(log_dir, 'a') as f:\n",
    "                f.write(f\"Epoch {epoch+1}/{EPOCH_NUM}\\n\")\n",
    "                f.write(f'train_loss: {np.mean(loss_list)}\\n')\n",
    "                f.write(str({k: v.item() for k, v in metrics_dict.items()}) + '\\n')\n",
    "                f.write(str({k: v.item() for k, v in neg_metrics_dict.items()}) + '\\n')\n",
    "\n",
    "        plt.plot(train_loss_list, label='train_loss')\n",
    "        plt.plot([i['acc'].item() for i in val_metrics_list], label='acc')\n",
    "        plt.plot([i['prec'].item() for i in val_metrics_list], label='prec')\n",
    "        plt.plot([i['rec'].item() for i in val_metrics_list], label='rec')\n",
    "        plt.plot([i['f1'].item() for i in val_metrics_list], label='f1')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'discriminate_logs/dis_wsss4luad_{dname}_r18_e5_run{run}.png')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsss4luad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
