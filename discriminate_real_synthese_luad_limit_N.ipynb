{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /home/fzj/.local/lib/python3.8/site-packages/horovod/torch/mpi_lib_v2.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still available.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# torch.random.manual_seed(42)\n",
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.label_list = label_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_list[idx])\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 40/40 [00:16<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.41164139546453954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 18/18 [00:06<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6060674786567688, 'f1': 0.4891645908355713, 'prec': 0.7549657821655273, 'rec': 0.5659489035606384}\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 40/40 [00:13<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.11806804279331118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 18/18 [00:07<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.9728322625160217, 'f1': 0.9726041555404663, 'prec': 0.9723385572433472, 'rec': 0.9728898406028748}\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 40/40 [00:13<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.03575878001283854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 18/18 [00:06<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.9782657623291016, 'f1': 0.9781147241592407, 'prec': 0.9773366451263428, 'rec': 0.9791486263275146}\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 40/40 [00:14<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.02312849119771272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 18/18 [00:07<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.9916232824325562, 'f1': 0.9915533065795898, 'prec': 0.9912586212158203, 'rec': 0.9918714165687561}\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 40/40 [00:13<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.01764708707924001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 18/18 [00:06<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.9789449572563171, 'f1': 0.9788310527801514, 'prec': 0.9777830839157104, 'rec': 0.9807612895965576}\n"
     ]
    }
   ],
   "source": [
    "for dname in ['bezier224_5_0.2_0.05_1d1']: # ['mosaic_2_112']:\n",
    "    for run in [4]: # range(1, 6):\n",
    "        for N_sample in [10]: # [10, 20, 30, 40]:\n",
    "            train_image_dir = f'data/LUAD-HistoSeg/train'\n",
    "            no_stain_norm_synthesize_image_dir = f\"data/LUAD-HistoSeg/limit_N/{dname}_N_{N_sample}_run{run}/img\"\n",
    "            log_dir = f'discriminate_logs_limit_N/luad_{dname}_N_{N_sample}_run{run}.txt'\n",
    "\n",
    "            train_image_list = sorted([os.path.join(train_image_dir, i) for i in os.listdir(train_image_dir) if \".png\" in i])\n",
    "            real_image_list = []\n",
    "            for image_name in train_image_list:\n",
    "                label_str = image_name.split(']')[0].split('[')[-1]\n",
    "                label_str = label_str.replace(' ', ',')\n",
    "                label = eval(label_str)\n",
    "                if sum(label) > 1:\n",
    "                    real_image_list.append(image_name)\n",
    "\n",
    "            synthesize_image_list = sorted([os.path.join(no_stain_norm_synthesize_image_dir, i) for i in os.listdir(no_stain_norm_synthesize_image_dir) if \".png\" in i])\n",
    "\n",
    "            np.random.shuffle(real_image_list)\n",
    "            np.random.shuffle(synthesize_image_list)\n",
    "\n",
    "            train_real_image_list = real_image_list[:int(len(real_image_list)*0.8)]\n",
    "            val_real_image_list = real_image_list[int(len(real_image_list)*0.8):]\n",
    "\n",
    "            train_synthesize_image_list = synthesize_image_list[:int(len(synthesize_image_list)*0.8)]\n",
    "            val_synthesize_image_list = synthesize_image_list[int(len(synthesize_image_list)*0.8):]\n",
    "\n",
    "            train_image_list = train_real_image_list[:5000] + train_synthesize_image_list[:5000]\n",
    "            train_label_list = [1] * 5000 + [0] * 5000\n",
    "\n",
    "            val_image_list = val_real_image_list + val_synthesize_image_list\n",
    "            val_label_list = [1] * len(val_real_image_list) + [0] * len(val_synthesize_image_list)\n",
    "\n",
    "            train_dataset = DiscriminatorDataset(train_image_list, train_label_list, transform=transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD)\n",
    "            ]))\n",
    "\n",
    "            val_dataset = DiscriminatorDataset(val_image_list, val_label_list, transform=transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD)\n",
    "            ]))\n",
    "\n",
    "            train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "            val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "            model = timm.create_model('resnet18', pretrained=False, num_classes=2)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "            # criterion = nn.BCEWithLogitsLoss()\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            metrics = torchmetrics.MetricCollection({ \n",
    "                'acc': torchmetrics.Accuracy(num_classes=2, average='micro'), \n",
    "                'prec': torchmetrics.Precision(num_classes=2, average='macro'), \n",
    "                'rec': torchmetrics.Recall(num_classes=2, average='macro'),\n",
    "                'f1': torchmetrics.F1Score(num_classes=2, average='macro')\n",
    "            }).cuda()\n",
    "\n",
    "            model = model.cuda()\n",
    "\n",
    "            EPOCH_NUM = 5\n",
    "            best_acc = 0\n",
    "            train_loss_list = []\n",
    "            val_metrics_list = []\n",
    "            for epoch in range(EPOCH_NUM):\n",
    "                print(f\"Epoch {epoch+1}/{EPOCH_NUM}\")\n",
    "                model.train()\n",
    "                loss_list = []\n",
    "                for batch in tqdm(train_dataloader, desc='train'):\n",
    "                    image, label = batch\n",
    "                    image = image.cuda()\n",
    "                    label = label.cuda()\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(image) # 1 real, 0 fake\n",
    "                    loss = criterion(output, label)\n",
    "                    loss_list.append(loss.item())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                print(f'train_loss: {np.mean(loss_list)}')\n",
    "                train_loss_list.append(np.mean(loss_list))\n",
    "\n",
    "                model.eval()\n",
    "                for batch in tqdm(val_dataloader, desc='val'):\n",
    "                    image, label = batch\n",
    "                    image = image.cuda()\n",
    "                    label = label.cuda()\n",
    "                    with torch.no_grad():\n",
    "                        output = model(image)\n",
    "                    metrics(output, label)\n",
    "                \n",
    "                metrics_dict = metrics.compute()\n",
    "                metrics.reset()\n",
    "                val_metrics_list.append(metrics_dict)\n",
    "                if metrics_dict['acc'] > best_acc:\n",
    "                    best_acc = metrics_dict['acc']\n",
    "                    torch.save(model.state_dict(), f\"weights_limit_N/dis_luad_{dname}_N_{N_sample}_r18_e{EPOCH_NUM}_run{run}.pth\")\n",
    "                print({k: v.item() for k, v in metrics_dict.items()})\n",
    "\n",
    "                with open(log_dir, 'a') as f:\n",
    "                    f.write(f\"Epoch {epoch+1}/{EPOCH_NUM}\\n\")\n",
    "                    f.write(f'train_loss: {np.mean(loss_list)}\\n')\n",
    "                    f.write(str({k: v.item() for k, v in metrics_dict.items()}) + '\\n')\n",
    "                \n",
    "            plt.plot(train_loss_list, label='train_loss')\n",
    "            plt.plot([i['acc'].item() for i in val_metrics_list], label='acc')\n",
    "            plt.plot([i['prec'].item() for i in val_metrics_list], label='prec')\n",
    "            plt.plot([i['rec'].item() for i in val_metrics_list], label='rec')\n",
    "            plt.plot([i['f1'].item() for i in val_metrics_list], label='f1')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'discriminate_logs_limit_N/dis_luad_{dname}_N_{N_sample}_r18_e{EPOCH_NUM}_run{run}.png')\n",
    "            plt.clf()\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_sample, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsss4luad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
