{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d180038f",
   "metadata": {},
   "source": [
    "# README\n",
    "Run this notebook to create the dataset for mosaic training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0cf606-ded3-45c0-8c42-ad3d650c8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import albumentations as albu\n",
    "\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# np.random.seed(42)\n",
    "# random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079032f0-5e42-4caf-9bfe-e7f0a3a3dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_label(file):\n",
    "    # [a: Tumor epithelial (TE), b: Necrosis (NEC), c: Lymphocyte (LYM), d: Tumor-associated stroma (TAS)]\n",
    "    if isinstance(file, Path):\n",
    "        file = str(file)\n",
    "    fname = file[:-4]\n",
    "    label_str = '[' + fname.split(']')[0].split('[')[-1] + ']'\n",
    "    label_str = label_str.replace(' ', ',')\n",
    "    label = eval(label_str)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23842bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_label(train_image_dir):\n",
    "    train_image_list = sorted(list(train_image_dir.glob('*.png')))\n",
    "\n",
    "    single_type_num = 0\n",
    "    only_tum_num = 0\n",
    "    only_nec_num = 0\n",
    "    only_lym_num = 0\n",
    "    only_tas_num = 0\n",
    "    \n",
    "    only_tum_list = []\n",
    "    only_nec_list = []\n",
    "    only_lym_list = []\n",
    "    only_tas_list = []\n",
    "\n",
    "    for train_image in train_image_list:\n",
    "        big_label = get_patch_label(train_image)\n",
    "        if np.sum(big_label) == 1:\n",
    "            single_type_num += 1\n",
    "            if big_label[0] == 1:\n",
    "                only_tum_num += 1\n",
    "                only_tum_list.append(train_image)\n",
    "            elif big_label[1] == 1:\n",
    "                only_nec_num += 1\n",
    "                only_nec_list.append(train_image)\n",
    "            elif big_label[2] == 1:\n",
    "                only_lym_num += 1\n",
    "                only_lym_list.append(train_image)\n",
    "            elif big_label[3] == 1:\n",
    "                only_tas_num += 1\n",
    "                only_tas_list.append(train_image)\n",
    "    print('only_tum_num:', len(only_tum_list))\n",
    "    print('only_nec_num:', len(only_nec_list))\n",
    "    print('only_lym_num:', len(only_lym_list))\n",
    "    print('only_tas_num:', len(only_tas_list))\n",
    "    \n",
    "    return only_tum_list, only_nec_list, only_lym_list, only_tas_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff6837",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d11986d-0f78-43f1-8353-9bf0514ddf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropAndConcatDataset(BaseDataset):    \n",
    "    def __init__(self, args, patch_num, patch_size, size=None):\n",
    "       \n",
    "        self.args = args\n",
    "        self.train_dir = Path(args.train_dir)\n",
    "        self.train_images = list(self.train_dir.glob('*.png'))\n",
    "        self.tum, self.nec, self.lym, self.tas = get_one_label(self.train_dir)\n",
    "        self.single_type_images = self.tum + self.nec + self.lym + self.tas\n",
    "        print(f'num of single type images: {len(self.single_type_images)}')\n",
    "\n",
    "        self.patch_num = patch_num\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.total_len = len(self.single_type_images) if size is None else size\n",
    "\n",
    "        self.crop_fn = albu.Compose([\n",
    "            albu.PadIfNeeded(min_height=self.patch_size, min_width=self.patch_size),\n",
    "            albu.RandomCrop(width=self.patch_size, height=self.patch_size)\n",
    "        ])\n",
    "        \n",
    "        self.transform = albu.Compose([\n",
    "            albu.Flip(),\n",
    "            albu.RandomRotate90(),\n",
    "        ])\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # np.random.seed(2022 + 2022 * i)\n",
    "        # random.seed(2022 + 2022 * i)\n",
    "        \n",
    "        H = W = self.patch_num * self.patch_size\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                (image_1, mask_1), (image_2, mask_2), (image_3, mask_3), (image_4, mask_4) = [self.create_one_image() for _ in range(4)] # [H, W, C]\n",
    "                image, mask = self.create_mosaic(H, W, image_1, mask_1, image_2, mask_2, image_3, mask_3, image_4, mask_4)\n",
    "                break            \n",
    "            except AssertionError as e:\n",
    "                print(e)\n",
    "\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "    def create_one_image(self):      \n",
    "        H = W = self.patch_num * self.patch_size\n",
    "        image = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "        mask = np.zeros((H, W), dtype=np.uint8)\n",
    "\n",
    "        for i in range(self.patch_num):\n",
    "            for j in range(self.patch_num):\n",
    "\n",
    "                tile_name = np.random.choice(self.single_type_images)\n",
    "                label = get_patch_label(tile_name)\n",
    "                assert sum(label) == 1\n",
    "                tile = np.asarray(Image.open(tile_name))\n",
    "                label = label.index(1)\n",
    "                tile_mask = np.full((tile.shape[0], tile.shape[1]), label)\n",
    "\n",
    "                sample = self.crop_fn(image=tile, mask=tile_mask)\n",
    "                tile = sample['image']\n",
    "                tile_mask = sample['mask']\n",
    "                \n",
    "                image[i*self.patch_size: (i+1)*self.patch_size, j*self.patch_size: (j+1)*self.patch_size] = tile\n",
    "                mask[i*self.patch_size: (i+1)*self.patch_size, j*self.patch_size: (j+1)*self.patch_size] = tile_mask\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def create_mosaic(self, H, W, image_1, mask_1, image_2, mask_2, image_3, mask_3, image_4, mask_4):\n",
    "        def get_transforms(height, width, p=0.5):\n",
    "            _transform = [\n",
    "                albu.Flip(p=p),\n",
    "                albu.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=p),\n",
    "                albu.RandomCrop(height, width),\n",
    "            ]\n",
    "            return albu.Compose(_transform)\n",
    "        \n",
    "        image = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "        mask = np.zeros((H, W), dtype=np.uint8)\n",
    "\n",
    "        h, w = int(H * (random.random()*0.6+0.2)), int(W * (random.random()*0.6+0.2))\n",
    "        h += h % 2\n",
    "        w += w % 2\n",
    "\n",
    "        transform_1 = get_transforms(height=h, width=w, p=0.8)\n",
    "        sample = transform_1(image=image_1, mask=mask_1)\n",
    "        image_1, mask_1 = sample['image'], sample['mask']\n",
    "\n",
    "        transform_2 = get_transforms(height=h, width=W-w, p=0.8)\n",
    "        sample = transform_2(image=image_2, mask=mask_2)\n",
    "        image_2, mask_2 = sample['image'], sample['mask']\n",
    "\n",
    "        transform_3 = get_transforms(height=H-h, width=w, p=0.8)\n",
    "        sample = transform_3(image=image_3, mask=mask_3)\n",
    "        image_3, mask_3 = sample['image'], sample['mask']\n",
    "\n",
    "        transform_4 = get_transforms(height=H-h, width=W-w, p=0.8)\n",
    "        sample = transform_4(image=image_4, mask=mask_4)\n",
    "        image_4, mask_4 = sample['image'], sample['mask']\n",
    "        \n",
    "        image[:h, :w, :] = image_1\n",
    "        image[:h, w:W, :] = image_2\n",
    "        image[h:H, :w, :] = image_3\n",
    "        image[h:H, w:W, :] = image_4\n",
    "    \n",
    "        mask[:h, :w] = mask_1\n",
    "        mask[:h, w:W] = mask_2\n",
    "        mask[h:H, :w] = mask_3\n",
    "        mask[h:H, w:W] = mask_4\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870458b6-05ed-4b12-b70d-0b690004282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace()\n",
    "# set to 2 and 112 for better performance\n",
    "patch_num = 2\n",
    "patch_size = 112\n",
    "N=10_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f81ab79-0451-4dd5-8e20-220c091d23e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 10\n",
      "only_nec_num: 10\n",
      "only_lym_num: 10\n",
      "only_tas_num: 10\n",
      "num of single type images: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:40<00:00, 62.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 10\n",
      "only_nec_num: 10\n",
      "only_lym_num: 10\n",
      "only_tas_num: 10\n",
      "num of single type images: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:38<00:00, 63.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 10\n",
      "only_nec_num: 10\n",
      "only_lym_num: 10\n",
      "only_tas_num: 10\n",
      "num of single type images: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:37<00:00, 63.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 10\n",
      "only_nec_num: 10\n",
      "only_lym_num: 10\n",
      "only_tas_num: 10\n",
      "num of single type images: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:38<00:00, 63.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 20\n",
      "only_nec_num: 20\n",
      "only_lym_num: 20\n",
      "only_tas_num: 20\n",
      "num of single type images: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:41<00:00, 62.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 20\n",
      "only_nec_num: 20\n",
      "only_lym_num: 20\n",
      "only_tas_num: 20\n",
      "num of single type images: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:40<00:00, 62.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 20\n",
      "only_nec_num: 20\n",
      "only_lym_num: 20\n",
      "only_tas_num: 20\n",
      "num of single type images: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:42<00:00, 61.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 20\n",
      "only_nec_num: 20\n",
      "only_lym_num: 20\n",
      "only_tas_num: 20\n",
      "num of single type images: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:42<00:00, 61.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 30\n",
      "only_nec_num: 30\n",
      "only_lym_num: 30\n",
      "only_tas_num: 30\n",
      "num of single type images: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:41<00:00, 61.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 30\n",
      "only_nec_num: 30\n",
      "only_lym_num: 30\n",
      "only_tas_num: 30\n",
      "num of single type images: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:40<00:00, 62.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 30\n",
      "only_nec_num: 30\n",
      "only_lym_num: 30\n",
      "only_tas_num: 30\n",
      "num of single type images: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:38<00:00, 63.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 30\n",
      "only_nec_num: 30\n",
      "only_lym_num: 30\n",
      "only_tas_num: 30\n",
      "num of single type images: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:40<00:00, 62.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 40\n",
      "only_nec_num: 40\n",
      "only_lym_num: 40\n",
      "only_tas_num: 40\n",
      "num of single type images: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:47<00:00, 59.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 40\n",
      "only_nec_num: 40\n",
      "only_lym_num: 40\n",
      "only_tas_num: 40\n",
      "num of single type images: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:44<00:00, 60.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 40\n",
      "only_nec_num: 40\n",
      "only_lym_num: 40\n",
      "only_tas_num: 40\n",
      "num of single type images: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:45<00:00, 60.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_tum_num: 40\n",
      "only_nec_num: 40\n",
      "only_lym_num: 40\n",
      "only_tas_num: 40\n",
      "num of single type images: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:42<00:00, 61.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "for N_sample in [10, 20, 30, 40]:\n",
    "    for run in range(1, 5):\n",
    "        args.train_dir = f\"./data/LUAD-HistoSeg/limit_N/one_label_N{N_sample}_run{run}\"\n",
    "        mosaic_data = Path(f\"./data/LUAD-HistoSeg/limit_N/mosaic_{patch_num}_{patch_size}_N_{N_sample}_run{run}\")\n",
    "        (mosaic_data / 'img').mkdir(parents=True, exist_ok=True)\n",
    "        (mosaic_data / 'mask').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        dataset = CropAndConcatDataset(args, patch_num=patch_num, patch_size=patch_size, size=N)\n",
    "\n",
    "        def func(i):\n",
    "            image, mask = dataset[i]\n",
    "            image = Image.fromarray(image)\n",
    "            palette = [0]*15\n",
    "            palette[0:3] = [205,51,51]          # Tumor epithelial (TE)\n",
    "            palette[3:6] = [0,255,0]            # Necrosis (NEC)\n",
    "            palette[6:9] = [65,105,225]         # Lymphocyte (LYM)\n",
    "            palette[9:12] = [255,165,0]         # Tumor-associated stroma (TAS)\n",
    "            palette[12:15] = [255, 255, 255]    # White background or exclude\n",
    "            mask = Image.fromarray(np.uint8(mask), mode='P')\n",
    "            mask.putpalette(palette)\n",
    "            image.save(mosaic_data / 'img' / f'{patch_num}_{patch_size}_{i}.png')\n",
    "            mask.save(mosaic_data / 'mask' / f'{patch_num}_{patch_size}_{i}.png')\n",
    "        def print_error(value):\n",
    "            print(\"error: \", value)\n",
    "\n",
    "        Parallel(n_jobs=4)(delayed(func)(i) for i in tqdm(range(N)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8244cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c5995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wsss4luad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "153d7fbbbee1d273a0ca8d1411d96d9bc2f994be0d513b7341e48284653310bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
